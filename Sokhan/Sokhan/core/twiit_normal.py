import unicodedata
import string
import time
from functools import lru_cache
import concurrent.futures
import numpy as np
import csv

COMBINED_TRANS = str.maketrans('', '', string.punctuation + string.whitespace + '@#')
NUMBER_TRANS = str.maketrans('0123456789', 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹')

class TurboNormalizer:
    def __init__(self):
        self.combined_trans = COMBINED_TRANS
        self.number_trans = NUMBER_TRANS
        self.diacritics = set('\u064b\u064c\u064d\u064e\u064f\u0650\u0651\u0652')
        self.suffixes = {'Ù‡Ø§', 'Ø§ÛŒ', 'ØªØ±', 'ØªØ±ÛŒ', 'ØªØ±ÛŒÙ†'}
    
    @lru_cache(maxsize=16384)
    def normalize_word(self, word: str) -> str:
        word = unicodedata.normalize('NFKC', word)
        word = ''.join(c for c in word if c not in self.diacritics)
        return word.translate(self.combined_trans).translate(self.number_trans).lower()
    
    def _normalize_chunk(self, sentence: str) -> str:
        sentence = unicodedata.normalize('NFKC', sentence.lower())
        sentence = ''.join(c for c in sentence if c not in self.diacritics)
        sentence = sentence.translate(self.combined_trans).translate(self.number_trans)
        
        # Ú©Ø§Ù‡Ø´ ØªÚ©Ø±Ø§Ø± Ø­Ø±ÙˆÙ
        result = []
        last_char = ''
        count = 0
        for char in sentence:
            if char == last_char:
                count += 1
                if count <= 2:
                    result.append(char)
            else:
                result.append(char)
                last_char = char
                count = 1
        sentence = ''.join(result)
        
        # Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† "Ù…ÛŒ" Ùˆ "Ù†Ù…ÛŒ"
        words = sentence.split()
        for i in range(len(words)):
            word = words[i]
            if word.startswith('Ù…ÛŒ') or word.startswith('Ù†Ù…ÛŒ'):
                prefix = 'Ù…ÛŒ' if word.startswith('Ù…ÛŒ') else 'Ù†Ù…ÛŒ'
                rest = word[len(prefix):]
                if rest:
                    words[i] = prefix + 'â€Œ' + rest
        
        # Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù¾Ø³ÙˆÙ†Ø¯Ù‡Ø§
        output = []
        i = 0
        while i < len(words):
            if i + 1 < len(words) and words[i + 1] in self.suffixes:
                output.append(words[i] + 'â€Œ' + words[i + 1])
                i += 2
            else:
                output.append(words[i])
                i += 1
        
        return ' '.join(output)
    
    def normalize_sentence(self, sentence: str) -> str:
        return self._normalize_chunk(sentence)
    
    def normalize_bulk(self, texts: list) -> list:
        if len(texts) < 100:
            return [self._normalize_chunk(t) for t in texts]
        text_array = np.array(texts, dtype=object)
        with concurrent.futures.ThreadPoolExecutor() as executor:
            results = list(executor.map(self._normalize_chunk, text_array))
        return results

def precision_timer(func):
    def wrapper(*args, **kwargs):
        func(*args, **kwargs)
        start = time.perf_counter_ns()
        result = func(*args, **kwargs)
        elapsed = (time.perf_counter_ns() - start) / 1e9
        return result, elapsed
    return wrapper

# Ø¯ÛŒØªØ§Ø³Øª Ù†Ù…ÙˆÙ†Ù‡ ØªÙˆÛŒÛŒØªØ±
twitter_dataset = [
    "Ø³Ù„Ø§Ù… Ú†Ø·ÙˆØ±ÛŒØŸ Ø§Ù…Ø±ÙˆØ² Ø®ÛŒÙ„ÛŒ Ù‡ÙˆØ§ Ø®ÙˆØ¨Ù‡!",
    "Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø¬Ø¯ÛŒØ¯ Ø±Ùˆ Ø¯ÛŒØ¯Ù… ÙˆØ§Ù‚Ø¹Ø§ Ø¹Ø§Ù„ÛŒ Ø¨ÙˆØ¯!!!",
    "Ú†Ø±Ø§ Ø§Ù†Ù‚Ø¯Ø± ØªØ±Ø§ÙÛŒÚ© Ø²ÛŒØ§Ø¯Ù‡ØŸØŸØŸ Ø®Ø³ØªÙ‡ Ø´Ø¯Ù…",
    "Ú©Ø§Ø´ ÛŒÙ‡ Ø±ÙˆØ² Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ±Ø³ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ…...",
    "Ø¯ÛŒØ±ÙˆØ² ÛŒÙ‡ Ú©ØªØ§Ø¨ Ø®ÙˆÙ†Ø¯Ù… Ø®ÛŒÙ„ÛŒ Ø¬Ø§Ù„Ø¨ Ø¨ÙˆØ¯ #Ú©ØªØ§Ø¨",
    "@ali Ø³Ù„Ø§Ù… Ø®ÙˆØ¨ÛŒØŸ Ú©Ø¬Ø§ÛŒÛŒØŸ",
    "Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ø§Ø² Ù‚Ø·Ø¹ Ø´Ø¯Ù‡ØŒ Ø§Ø¹ØµØ§Ø¨Ù… Ø®ÙˆØ±Ø¯ Ø´Ø¯!!!",
    "Ø¨ÛŒØ§ Ø§ÛŒÙ†Ùˆ Ø¨Ø¨ÛŒÙ† Ú†Ù‡ Ø¨Ø§Ø­Ø§Ù„Ù‡ https://t.co/test",
    "Ø§Ù…Ø±ÙˆØ² Ø­Ø§Ù„Ù… Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ¨Ù‡ ğŸ˜Š",
    "Ù†Ù…ÛŒâ€ŒØ¯ÙˆÙ†Ù… Ú†Ø±Ø§ Ø§Ù†Ù‚Ø¯Ø± Ø®ÙˆØ§Ø¨Ù… Ù…ÛŒØ§Ø¯...",
    "Ù‡ÙˆØ§ÛŒ Ø¨Ø§Ø±ÙˆÙ†ÛŒ Ø±Ùˆ Ø®ÛŒÙ„ÛŒ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù… #Ø¨Ø§Ø±ÙˆÙ†",
    "Ø§ÛŒÙ† ØºØ°Ø§ Ø±Ùˆ Ø¯Ø±Ø³Øª Ú©Ø±Ø¯Ù… Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ´Ù…Ø²Ù‡ Ø´Ø¯!",
    "Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ù…ØªØ­Ø§Ù† Ø¯Ø§Ø±Ù… Ø¯Ø¹Ø§ Ú©Ù† Ø¨Ø±Ø§Ù… @maryam",
    "Ú†Ø±Ø§ Ù‚ÛŒÙ…ØªØ§ Ø§Ù†Ù‚Ø¯Ø± Ú¯Ø±ÙˆÙ† Ø´Ø¯Ù‡ØŸØŸ",
    "ÛŒÙ‡ Ú†Ø§ÛŒÛŒ Ø¯Ø§Øº Ø§Ù„Ø§Ù† Ù…ÛŒâ€ŒÚ†Ø³Ø¨Ù‡...",
    "ÙÙˆØªØ¨Ø§Ù„ Ø¯ÛŒØ´Ø¨ Ø±Ùˆ Ø¯ÛŒØ¯ÛŒØŸ Ú†Ù‡ Ú¯Ù„ÛŒ Ø²Ø¯!",
    "Ú©Ø§Ø´ ØªØ¹Ø·ÛŒÙ„Ø§Øª Ø²ÙˆØ¯ØªØ± Ø¨Ø±Ø³Ù‡ #ØªØ¹Ø·ÛŒÙ„Ø§Øª",
    "Ø§ÛŒÙ† Ø¢Ù‡Ù†Ú¯ Ø¬Ø¯ÛŒØ¯ Ø±Ùˆ Ú¯ÙˆØ´ Ø¨Ø¯Ù‡ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ø³Øª!",
    "Ø¯Ø§Ø±Ù… Ù…ÛŒâ€ŒØ±Ù… Ø®Ø±ÛŒØ¯ØŒ Ú†ÛŒØ²ÛŒ Ù„Ø§Ø²Ù… Ø¯Ø§Ø±ÛŒØŸ",
    "Ú†Ø±Ø§ Ø§ÛŒÙ†Ù‚Ø¯Ø± Ú©Ø§Ø±Ø§Ù… Ø¹Ù‚Ø¨ Ø§ÙØªØ§Ø¯Ù‡ØŸØŸØŸ",
    "Ø§Ù…Ø±ÙˆØ² ÛŒÙ‡ Ø³Ú¯ Ø¨Ø§Ù…Ø²Ù‡ Ø¯ÛŒØ¯Ù… Ø®ÛŒÙ„ÛŒ Ú©ÛŒÙˆØª Ø¨ÙˆØ¯ ğŸ˜",
    "Ù†Ù…ÛŒâ€ŒØªÙˆÙ†Ù… ØªØµÙ…ÛŒÙ… Ø¨Ú¯ÛŒØ±Ù… Ú†ÛŒ Ø¨Ù¾ÙˆØ´Ù…...",
    "Ù‡Ù…Ù‡â€ŒÚ†ÛŒØ² Ú¯Ø±ÙˆÙ† Ø´Ø¯Ù‡ Ø¯ÛŒÚ¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´Ù‡ Ø²Ù†Ø¯Ú¯ÛŒ Ú©Ø±Ø¯!",
    "Ø¯ÛŒØ´Ø¨ ØªØ§ ØµØ¨Ø­ Ø¨ÛŒØ¯Ø§Ø± Ø¨ÙˆØ¯Ù…ØŒ Ø§Ù„Ø§Ù† Ù†Ø§Ø¨ÙˆØ¯Ù…",
    "ÛŒÙ‡ Ø§ÛŒØ¯Ù‡ Ø¨Ø§Ø­Ø§Ù„ Ø¨Ù‡ Ø°Ù‡Ù†Ù… Ø±Ø³ÛŒØ¯ #Ø§ÛŒØ¯Ù‡",
    "Ø³Ù„Ø§Ù…Ù…Ù…Ù…Ù…Ù… Ø¨Ù‡ Ù‡Ù…Ù‡ Ø¯ÙˆØ³ØªØ§Ù…!",
    "Ø§ÛŒÙ† Ø¹Ú©Ø³ Ø±Ùˆ Ø¨Ø¨ÛŒÙ† Ú†Ù‚Ø¯Ø± Ù‚Ø´Ù†Ú¯Ù‡ https://t.co/pic",
    "Ø§Ù…Ø±ÙˆØ² Ø®ÛŒÙ„ÛŒ Ú©Ø§Ø± Ø¯Ø§Ø±Ù… Ø³Ø±Ù… Ø´Ù„ÙˆØºÙ‡",
    "Ú†Ø±Ø§ Ù‡Ù…ÛŒØ´Ù‡ Ú©Ø§Ø±Ø§ Ø±Ùˆ Ø¯Ù‚ÛŒÙ‚Ù‡ Ù†ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù…ØŸ",
    "Ú©Ø§Ø´ ÛŒÙ‡ Ø³ÙØ± Ø¨Ø±Ù… Ø­Ø§Ù„Ù… Ø¹ÙˆØ¶ Ø´Ù‡...",
    "Ø§ÛŒÙ† Ø¬ÙˆÚ© Ø±Ùˆ Ø´Ù†ÛŒØ¯ÛŒØŸ Ø®ÛŒÙ„ÛŒ Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø± Ø¨ÙˆØ¯!",
    "Ø¯Ø§Ø±Ù… ÙÛŒÙ„Ù… Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ù…ØŒ Ù…Ø²Ø§Ø­Ù… Ù†Ø´ÛŒØ¯!",
    "Ù‡ÙˆØ§ Ø®ÛŒÙ„ÛŒ Ø³Ø±Ø¯Ù‡ØŒ Ù¾ØªÙˆ Ù¾ÛŒÚ† Ø´Ø¯Ù…",
    "Ú†Ù‚Ø¯Ø± Ø¯Ù„Ù… Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ³ØªØ§Ù… ØªÙ†Ú¯ Ø´Ø¯Ù‡...",
    "Ø§ÛŒÙ† Ø¢Ø¯Ù…Ø§ Ú†Ø±Ø§ Ø§Ù†Ù‚Ø¯Ø± ØºØ± Ù…ÛŒâ€ŒØ²Ù†Ù†ØŸØŸ",
    "ÛŒÙ‡ Ù‚Ù‡ÙˆÙ‡ Ø§Ù„Ø§Ù† Ù…Ø¹Ø¬Ø²Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ â˜•",
    "Ø§Ù…Ø´Ø¨ Ù…Ù‡Ù…ÙˆÙ† Ø¯Ø§Ø±ÛŒÙ…ØŒ Ú†ÛŒ Ø¨Ù¾Ø²Ù…ØŸ",
    "Ú†Ø±Ø§ Ø§ÛŒÙ† Ú©Ø§Ø± Ø¯Ø±Ø³Øª Ù¾ÛŒØ´ Ù†Ù…ÛŒâ€ŒØ±Ù‡ØŸØŸØŸ",
    "Ø¯Ù„Ù… ÛŒÙ‡ Ø·Ø¨ÛŒØ¹Øªâ€ŒÚ¯Ø±Ø¯ÛŒ Ù…ÛŒâ€ŒØ®ÙˆØ§Ø¯ #Ø·Ø¨ÛŒØ¹Øª",
    "Ø§ÛŒÙ† Ø³Ø±ÛŒØ§Ù„ Ø¬Ø¯ÛŒØ¯ Ø®ÛŒÙ„ÛŒ Ù‚Ø´Ù†Ú¯Ù‡ØŒ Ø¨Ø¨ÛŒÙ†ÛŒØ¯Ø´!",
    "Ø§Ù…Ø±ÙˆØ² ØªÙˆÙ„Ø¯Ù…Ù‡ØŒ ØªØ¨Ø±ÛŒÚ© ÛŒØ§Ø¯ØªÙˆÙ† Ù†Ø±Ù‡ ğŸ‰",
    "Ú©Ø§Ø´ ÛŒÙ‡ Ú©Ù… Ø¢ÙØªØ§Ø¨ Ø¨Ø¨ÛŒÙ†ÛŒÙ…...",
    "Ú†Ø±Ø§ Ø§Ù†Ù‚Ø¯Ø± Ú¯Ø±Ø³Ù†Ù…Ù‡ØŸØŸØŸ",
    "ÛŒÙ‡ Ø¢Ù‡Ù†Ú¯ Ù‚Ø¯ÛŒÙ…ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù… Ø®Ø§Ø·Ø±Ø§ØªÙ… Ø²Ù†Ø¯Ù‡ Ø´Ø¯",
    "Ø³Ù„Ø§Ù… Ø¨Ù‡ Ù‡Ù…Ù‡ØŒ Ø±ÙˆØ²ØªÙˆÙ† Ú†Ø·ÙˆØ± Ø¨ÙˆØ¯ØŸ",
    "Ø§ÛŒÙ†ØªØ±Ù†Øª Ø³Ø±Ø¹ØªØ´ Ø§ÙØªØ¶Ø§Ø­Ù‡!",
    "Ø¯Ù„Ù… Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ ØªÙ†Ú¯ Ø´Ø¯Ù‡ #Ø¯Ø±ÛŒØ§",
    "Ú†Ø±Ø§ Ø§ÛŒÙ†Ù‚Ø¯Ø± Ú©Ø§Ø±Ø§Ù… Ø²ÛŒØ§Ø¯ Ø´Ø¯Ù‡ØŸ",
    "ÛŒÙ‡ Ú†Ø§ÛŒÛŒ Ø¨Ø§ Ø¯ÙˆØ³ØªØ§Ù… Ù…ÛŒâ€ŒÚ†Ø³Ø¨Ù‡ Ø§Ù„Ø§Ù†",
    "ÙÛŒÙ„Ù… Ø¢Ø®Ø± Ù‡ÙØªÙ‡ Ø±Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯ÛŒØŸ",
    "Ø§Ù…Ø±ÙˆØ² Ø®ÛŒÙ„ÛŒ Ø®Ù†Ø¯ÛŒØ¯Ù…ØŒ Ø±ÙˆØ² Ø®ÙˆØ¨ÛŒ Ø¨ÙˆØ¯",
    "Ú†Ø±Ø§ Ø§ÛŒÙ†Ù‚Ø¯Ø± Ù‡ÙˆØ§ Ø¢Ù„ÙˆØ¯Ù‡â€ŒØ³ØªØŸØŸ",
    "Ú©Ø§Ø´ Ù…ÛŒâ€ŒØ´Ø¯ Ø²Ù…Ø§Ù† Ø±Ùˆ Ù†Ú¯Ù‡ Ø¯Ø§Ø´Øª...",
    "ÛŒÙ‡ Ø¹Ú©Ø³ Ù‚Ø´Ù†Ú¯ Ú¯Ø±ÙØªÙ… Ø¨Ø°Ø§Ø±Ù… ØªÙˆÛŒÛŒØªØ±",
    "Ø¯Ù„Ù… ÛŒÙ‡ Ú©ÛŒÚ© Ø´Ú©Ù„Ø§ØªÛŒ Ù…ÛŒâ€ŒØ®ÙˆØ§Ø¯ ğŸ«",
    "Ú†Ø±Ø§ Ù‡Ù…ÛŒØ´Ù‡ Ù‡Ù…Ù‡â€ŒÚ†ÛŒØ² Ú¯Ø±ÙˆÙ† Ù…ÛŒâ€ŒØ´Ù‡ØŸ",
    "Ø§Ù…Ø´Ø¨ Ù…Ø§Ù‡ Ø®ÛŒÙ„ÛŒ Ù‚Ø´Ù†Ú¯Ù‡ØŒ Ø¯ÛŒØ¯ÛŒØ´ØŸ",
    "Ø¯Ø§Ø±Ù… Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù… Ø¨Ø±Ø§ÛŒ Ù‡ÙØªÙ‡ Ø¨Ø¹Ø¯",
    "Ú†Ù‚Ø¯Ø± Ø¯Ù„Ù… Ø¨Ø±Ø§ÛŒ Ø®ÙˆÙ†ÙˆØ§Ø¯Ù… ØªÙ†Ú¯ Ø´Ø¯Ù‡...",
    "Ø§ÛŒÙ† Ø¢Ù‡Ù†Ú¯ Ø±Ùˆ ØªÚ©Ø±Ø§Ø± Ø²Ø¯Ù…ØŒ Ù…Ø­Ø´Ø±Ù‡!",
    "Ø§Ù…Ø±ÙˆØ² Ø®ÛŒÙ„ÛŒ Ø§Ù†Ø±Ú˜ÛŒ Ø¯Ø§Ø±Ù… ğŸ˜Š",
    "Ú†Ø±Ø§ Ø§ÛŒÙ† Ú©Ø§Ø±Ø§ ØªÙ…ÙˆÙ…ÛŒ Ù†Ø¯Ø§Ø±Ù‡ØŸØŸ",
    "ÛŒÙ‡ Ø±ÙˆØ² Ø¢Ø±ÙˆÙ… Ù…ÛŒâ€ŒØ®ÙˆØ§Ù… Ø¨Ø¯ÙˆÙ† Ø¯Ø±Ø¯Ø³Ø±",
    "Ø§ÛŒÙ† Ø¨Ø§Ø²ÛŒ Ø¬Ø¯ÛŒØ¯ Ø±Ùˆ Ø§Ù…ØªØ­Ø§Ù† Ú©Ø±Ø¯ÛŒØŸ",
    "Ø³Ù„Ø§Ù…Ù…Ù…Ù…ØŒ Ú†Ø·ÙˆØ±ÛŒØ¯ Ù‡Ù…Ù‡ØŸ",
    "Ú†Ø±Ø§ Ø§Ù†Ù‚Ø¯Ø± Ø®ÙˆØ§Ø¨Ù… Ù…ÛŒØ§Ø¯ Ø§Ù„Ø§Ù†ØŸ",
    "Ø¯Ù„Ù… ÛŒÙ‡ Ø³ÙØ± Ø¬Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÛŒâ€ŒØ®ÙˆØ§Ø¯",
    "Ø§ÛŒÙ† ØºØ°Ø§ Ø±Ùˆ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ØŒ Ø¹Ø§Ù„ÛŒÙ‡!",
    "Ø§Ù…Ø±ÙˆØ² ÛŒÙ‡ Ø§Ø´ØªØ¨Ø§Ù‡ Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø± Ú©Ø±Ø¯Ù…",
    "Ú†Ù‚Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ²Ø§ Ø²ÙˆØ¯ Ù…ÛŒâ€ŒÚ¯Ø°Ø±Ù‡...",
    "Ú©Ø§Ø´ ÛŒÙ‡ Ú©Ù… Ù‡ÙˆØ§ Ø®Ù†Ú©â€ŒØªØ± Ø¨Ø´Ù‡",
    "ÛŒÙ‡ Ø§ÛŒØ¯Ù‡ Ø¯Ø§Ø±Ù… Ø¨Ø±Ø§ØªØŒ Ù†Ø¸Ø±Øª Ú†ÛŒÙ‡ØŸ",
    "Ú†Ø±Ø§ Ø§ÛŒÙ†Ù‚Ø¯Ø± Ú©Ø§Ø±Ø§Ù… Ø¹Ù‚Ø¨ Ø§ÙØªØ§Ø¯Ù‡ØŸØŸ",
    "Ø§Ù…Ø´Ø¨ Ø³ØªØ§Ø±Ù‡â€ŒÙ‡Ø§ Ø®ÛŒÙ„ÛŒ Ù‚Ø´Ù†Ú¯Ù†",
    "Ø¯Ø§Ø±Ù… Ú†Ø§ÛŒÛŒ Ù…ÛŒâ€ŒØ®ÙˆØ±Ù…ØŒ ØªÙˆ Ú†ÛŒØŸ",
    "Ú†Ù‚Ø¯Ø± Ø¯Ù„Ù… Ø¨Ø±Ø§ÛŒ ØªØ§Ø¨Ø³ØªÙˆÙ† ØªÙ†Ú¯ Ø´Ø¯Ù‡",
    "Ø§ÛŒÙ† Ù‡ÙØªÙ‡ Ø®ÛŒÙ„ÛŒ Ø³Ø®Øª Ø¨ÙˆØ¯ Ø¨Ø±Ø§Ù…",
    "ÛŒÙ‡ ÙÛŒÙ„Ù… Ù‚Ø¯ÛŒÙ…ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù… Ø¨Ø¨ÛŒÙ†Ù…",
    "Ø³Ù„Ø§Ù… Ø¨Ù‡ Ù‡Ù…Ù‡ØŒ Ø­Ø§Ù„Ù… Ø®ÙˆØ¨Ù‡!",
    "Ú†Ø±Ø§ Ø§ÛŒÙ†Ù‚Ø¯Ø± Ù‡Ù…Ù‡â€ŒÚ†ÛŒØ² Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØ³ØªØŸ",
    "Ú©Ø§Ø´ ÛŒÙ‡ Ø±ÙˆØ² Ø¨Ø¯ÙˆÙ† Ú¯ÙˆØ´ÛŒ Ø¨Ø§Ø´Ù…...",
    "Ø§Ù…Ø±ÙˆØ² ÛŒÙ‡ Ú©Ø§Ø± Ø¨Ø§Ø­Ø§Ù„ Ú©Ø±Ø¯Ù…",
    "Ú†Ù‚Ø¯Ø± Ø§ÛŒÙ† Ø¢Ù‡Ù†Ú¯ Ø­Ø³ Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø±Ù‡",
    "Ø¯Ù„Ù… ÛŒÙ‡ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ±ÙˆÛŒ Ù…ÛŒâ€ŒØ®ÙˆØ§Ø¯",
    "Ú†Ø±Ø§ Ø§ÛŒÙ† Ú©Ø§Ø± Ø¯Ø±Ø³Øª Ù†Ù…ÛŒâ€ŒØ´Ù‡ØŸØŸ",
    "ÛŒÙ‡ Ø¹Ú©Ø³ Ø§Ø² ØºØ±ÙˆØ¨ Ú¯Ø±ÙØªÙ… Ù‚Ø´Ù†Ú¯ Ø´Ø¯",
    "Ø§Ù…Ø´Ø¨ Ø´Ø§Ù… Ú†ÛŒ Ø¨Ø®ÙˆØ±ÛŒÙ…ØŸ",
    "Ú†Ù‚Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ²Ø§ Ø®Ø³ØªÙ‡â€ŒÙ…...",
    "Ú©Ø§Ø´ ÛŒÙ‡ ØªØ¹Ø·ÛŒÙ„ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¯Ø§Ø´ØªÛŒÙ…",
    "ÛŒÙ‡ Ø¬ÙˆÚ© Ø¨Ú¯Ù… Ø¨Ø®Ù†Ø¯ÛŒÙ…ØŸ",
    "Ø¯Ø§Ø±Ù… Ø¨Ù‡ ÛŒÙ‡ Ø³ÙØ± ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù…",
    "Ú†Ø±Ø§ Ø§Ù†Ù‚Ø¯Ø± Ù‡Ù…Ù‡â€ŒÚ†ÛŒØ² Ú¯Ø±ÙˆÙ†Ù‡ØŸ",
    "Ø§Ù…Ø±ÙˆØ² ÛŒÙ‡ Ø®Ø¨Ø± Ø®ÙˆØ¨ Ø´Ù†ÛŒØ¯Ù…",
    "Ú†Ù‚Ø¯Ø± Ø¯Ù„Ù… Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù ØªÙ†Ú¯ Ø´Ø¯Ù‡",
    "ÛŒÙ‡ Ø¢Ù‡Ù†Ú¯ Ø´Ø§Ø¯ Ø¨Ø°Ø§Ø± Ø­Ø§Ù„Ù… Ø¹ÙˆØ¶ Ø´Ù‡",
    "Ø³Ù„Ø§Ù…Ù…Ù…Ù…Ù…ØŒ Ú†Ø·ÙˆØ±ÛŒØ¯ Ø¯ÙˆØ³ØªØ§Ù…ØŸ",
    "Ú†Ø±Ø§ Ø§ÛŒÙ† Ú©Ø§Ø±Ø§ Ø§Ù†Ù‚Ø¯Ø± Ø·ÙˆÙ„ Ù…ÛŒâ€ŒÚ©Ø´Ù‡ØŸ",
    "Ø§Ù…Ø´Ø¨ ÛŒÙ‡ ÙÛŒÙ„Ù… Ú©Ù…Ø¯ÛŒ Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ù…",
    "Ú©Ø§Ø´ ÛŒÙ‡ Ø±ÙˆØ² Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ±Ø³ Ø¨Ø§Ø´Ù‡"
]

if __name__ == "__main__":
    normalizer = TurboNormalizer()
    
    tests = {
        "ØªÚ© Ú©Ù„Ù…Ù‡ Ø³Ø§Ø¯Ù‡": ("TEST!", normalizer.normalize_word),
        "Ø¬Ù…Ù„Ù‡ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯": ("Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† TEST Ø¨Ø§ Ø¹Ù„Ø§Ø¦Ù… !@# Ø³Ø¬Ø§ÙˆÙ†Ø¯ÛŒ Ùˆ   ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø§Ø³Øª!!!", normalizer.normalize_sentence),
        "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú¯Ø±ÙˆÙ‡ÛŒ": (twitter_dataset, normalizer.normalize_bulk),
        "ØªÙˆÛŒÛŒØª Ù†Ù…ÙˆÙ†Ù‡": ("Ø³Ù„Ø§Ù… @ali Ú†Ø·ÙˆØ±ÛŒØŸ #Ø¬Ø§Ù„Ø¨ Ø§ÛŒÙ†Ùˆ Ø¨Ø¨ÛŒÙ†Ù…Ù…Ù… https://t.co/test ğŸ˜‚ Û³.Û±Û´", normalizer.normalize_sentence)
    }
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± CSV
    with open('normalized_tweets.csv', 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['Original Text', 'Normalized Text', 'Execution Time (s)'])  # Ø³Ø±Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        
        for name, (data, func) in tests.items():
            result, elapsed = precision_timer(func)(data)
            print(f"âœ… ØªØ³Øª {name}")
            print(f"â± Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: {elapsed:.10f} Ø«Ø§Ù†ÛŒÙ‡")
            print(f"ğŸ“Š Ø­Ø¬Ù… Ø¯Ø§Ø¯Ù‡: {len(data) if isinstance(data, list) else len(data.split())}")
            
            if isinstance(result, str):  # Ø¨Ø±Ø§ÛŒ ØªÚ© Ù…ØªÙ†â€ŒÙ‡Ø§
                writer.writerow([data, result, elapsed])
                print(f"ğŸ¯ Ù†Ù…ÙˆÙ†Ù‡ Ø®Ø±ÙˆØ¬ÛŒ: {result[:75] + '...' if len(result) > 75 else result}")
            else:  # Ø¨Ø±Ø§ÛŒ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ (Ù…Ø«Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú¯Ø±ÙˆÙ‡ÛŒ)
                for orig, norm in zip(data, result):
                    writer.writerow([orig, norm, elapsed / len(data)])  # Ø²Ù…Ø§Ù† ØªÙ‚Ø±ÛŒØ¨ÛŒ Ù‡Ø± ØªÙˆÛŒÛŒØª
                print(f"ğŸ¯ Ù†Ù…ÙˆÙ†Ù‡ Ø®Ø±ÙˆØ¬ÛŒ: {result[0][:75] + '...' if len(result[0]) > 75 else result[0]}")
            print("-" * 80)
    
    print("Ù†ØªØ§ÛŒØ¬ Ø¯Ø± ÙØ§ÛŒÙ„ 'normalized_tweets.csv' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!")